{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importamos librerías\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.python.keras.layers import Convolution2D, MaxPooling2D\n",
    "from tensorflow.python.keras import backend as Keras\n",
    "Keras.clear_session() #Si había una sesión de keras abierto, la cierro para trabajar desde cero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametros de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_entrenamiento = './Señales/Entrenamiento' #Directorios donde estan las imagenes\n",
    "datos_validacion = './Señales/Prueba' #Directorios donde estan las imagenes\n",
    "epocas = 5 #Numero de veces que va a iterar sobre todo el set de datos durante el entrenamiento\n",
    "altura, longitud = 30, 30 #Tamaño al cual va a procesar las imagenes\n",
    "tamaño_lote = 32 #Cantidad de imagenes a procesar a la vez\n",
    "pasos = 1000 #Durante un paso, un lote es de imagenes es procesado. Indica la cantidad de veces que va a procesar cada lote en cada epoca.\n",
    "pasos_validacion = 200 #Al final de cada epoca se corren 200 pasos con los set de datos de validacion\n",
    "filtrosConv1 = 32 #El numero de filtros que aplicara en la primer convolución\n",
    "filtrosConv2 = 64 #La profundidad de la imagen con una convolucion sera de 32 y con dos convoluciones sera de 64\n",
    "tamaño_filtro1 = (3,3) #Tamaño del filtro que usa la primer convolucion. Altura 3 y longitud 3\n",
    "tamaño_filtro2 = (2,2)\n",
    "tamaño_pool = (2,2) #Tamaño del filtro del max pulling\n",
    "clases = 60 #Numero de clases. Cantidad de carpetas con imagenes o set de imagenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-procesamiento de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4284 images belonging to 60 classes.\n",
      "Found 2411 images belonging to 60 classes.\n"
     ]
    }
   ],
   "source": [
    "#Pre-procesamiento de imagenes para luego enviarlas a la red neuronal (Generador + transformacion de imagenes)\n",
    "#Generador dice como va a preprocesar la informacion\n",
    "entrenamiento_datagen = ImageDataGenerator( #Set de datos de entrenamiento\n",
    "    rescale=1./255, #Cada uno de los pixeles tiene un rango de 0 a 255, en este caso todos los valores de pixeles tendran valores de 0 a 1\n",
    "    shear_range=0.3, #Inclina la imagen para que el algoritmo aprenda a reconocer imagenes en todos los sentidos\n",
    "    zoom_range=0.3, #Hace zoom para que aprenda a que no siempre aparecen \"las señales completos\"\n",
    "    horizontal_flip = True #Toma una imagen y la invierte para que la red neuronal aprenda direccionalidad\n",
    ")\n",
    "\n",
    "validacion_datagen = ImageDataGenerator( #Set de datos de validacion\n",
    "    rescale=1. / 255, # Cada uno de los pixeles tiene un rango de 0 a 255, en este caso todos los valores de pixeles tendran valores de 0 a 1\n",
    "                      #Solo se las escala porque para validarlas no queremos hacerle zoom, girarla ni nada de eso\n",
    ")\n",
    "\n",
    "imagen_entrenamiento = entrenamiento_datagen.flow_from_directory( #Entra al directorio Señales/Entrenamiento, abre todas las carpetas, las procesa a altuna y longitud especificada\n",
    "    #las procesa en un tamaño_lote de 32, y class_mode = 'categorical' es porque es una clasificacion categorica\n",
    "    datos_entrenamiento,\n",
    "    target_size=(altura, longitud),\n",
    "    batch_size=tamaño_lote,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "imagen_validacion = validacion_datagen.flow_from_directory(\n",
    "    datos_validacion,\n",
    "    target_size=(altura, longitud),\n",
    "    batch_size=tamaño_lote,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de red CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=Sequential() #La red que va a generar va a ser secuencial, es decir, son varias capas apiladas entre ellas\n",
    "\n",
    "cnn.add(Convolution2D(filtrosConv1, tamaño_filtro1, padding='same', input_shape=(altura, longitud, 3), activation='relu')) #Añadimos la primer capa convolucional input_shape tiene altura, longitud y 3 canales (RGB)\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=tamaño_pool)) #Añado primer capa de maxpulling\n",
    "\n",
    "cnn.add(Convolution2D(filtrosConv2, tamaño_filtro2, padding='same', activation='relu')) #Añado segunda capa convolucional\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=tamaño_pool)) #Añado segunda capa de maxpulling\n",
    "\n",
    "#Empezamos clasificacion\n",
    "\n",
    "cnn.add(Flatten()) #Hacemos a la imagen en una sola dimension. Aplana la informacion\n",
    "cnn.add(Dense(265, activation='relu')) #Manda toda la info plana a una capa que tiene 265 capas\n",
    "cnn.add(Dropout(0.5)) #Se apaga el 50% de las neuronas de Dense265 para evitar sobreajustar: ya que si todo el tiempo todas las neuronas estan activadas puede que las neuronas aprendan un camino especifico para clasificar señales,\n",
    "#entonces, de manera aleatoria en cada paso solo activa el 50% de las neutoras para aprender caminos alternos\n",
    "cnn.add(Dense(clases, activation='softmax')) #Softmax hace que te diga que probabilidades hay que sea cada una de las señales con un %. La que mas alto % tiene es la que muestra como precicción\n",
    "\n",
    "cnn.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy']) #Compila el algoritmo, con parametros para optimizarlo:\n",
    "#loss: durante el entrenamiento, su funcion de perdida (es decir que el algoritmo vea que tan bien o que tan mal va) va a ser categorical_crossentrpy\n",
    "#optimizer: usamos Adam\n",
    "#metrics: usamos accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Por ultimo para entrenar el algoritmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 1.1395 - accuracy: 0.6952 - val_loss: 0.3671 - val_accuracy: 0.9000\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.3429 - accuracy: 0.8901 - val_loss: 0.2330 - val_accuracy: 0.9377\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2140 - accuracy: 0.9316 - val_loss: 0.2043 - val_accuracy: 0.9498\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1677 - accuracy: 0.9446 - val_loss: 0.1946 - val_accuracy: 0.9560\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1361 - accuracy: 0.9565 - val_loss: 0.2029 - val_accuracy: 0.9569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d2cbc86c48>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(imagen_entrenamiento, epochs=epocas, steps_per_epoch=pasos, validation_data=imagen_validacion, validation_steps=pasos_validacion) #Aqui le digo que va a entrenar la red neuronal con imagen_entrenamiento, le asigno los pasos, las epocas, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardamos el modelo y los pesos en un archivo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir='./modelo/'\n",
    "if not os.path.exists(dir): #Si no existe una carpeta que se llama modelo\n",
    "    os.mkdir(dir) #Genera una carpeta que se llama modelo\n",
    "\n",
    "cnn.save('./modelo/modelo.h5')  #Guarda la estructura del modelo\n",
    "cnn.save_weights('./modelo/pesos.h5') #Guarda los pesos que tiene cada una de las capas que ya entreno"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
